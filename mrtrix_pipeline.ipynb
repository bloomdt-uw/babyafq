{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dHCP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhcp_tractography_pipeline(subject, session, aws_access_key, aws_secret_key, dilation_size=12, streamline_count=2000000, local_env=False):\n",
    "    \"\"\"\n",
    "    For each `subject`, `session` pair run tractography pipeline.\n",
    "    \n",
    "    0. Perpare local environment\n",
    "    1. Generate isotropic DWI files\n",
    "    2. Realign DWI to anatomy using rigid transformation\n",
    "    3. Estimate CSD response function\n",
    "    4. Reassign ribbon values\n",
    "    5. Generate five-tissue-type (5TT) segmented tissue image\n",
    "    6. Tractography\n",
    "    7. Create BIDS derivatives\n",
    "    8. Upload to s3\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subject : string\n",
    "    session : string\n",
    "    aws_access_key : string\n",
    "    aws_secret_key : string\n",
    "    streamline_count : int\n",
    "    local_env : boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "    import os\n",
    "    from os.path import exists, join\n",
    "    import s3fs\n",
    "    import json\n",
    "    \n",
    "    fs = s3fs.S3FileSystem(\n",
    "        key=aws_access_key,\n",
    "        secret=aws_secret_key\n",
    "    )\n",
    "    \n",
    "    def print_quiet(string):\n",
    "        \"\"\"\n",
    "        mrtrix doesn't provide a way to conviently supress progress messages without\n",
    "        also supressing informational messages. \n",
    "        \n",
    "        filter stderr/stdout before printing\n",
    "\n",
    "        \"\"\"\n",
    "        import re\n",
    "        \n",
    "        # remove any line that looks like a progress message\n",
    "        string = re.sub(r'.*\\[[0-9 ]{3}\\%\\].*\\n?', '', string)\n",
    "\n",
    "        # remove empty lines\n",
    "        string = re.sub(r'^\\n$', '', string)\n",
    "        \n",
    "        # remove any leading or trailing whitespace\n",
    "        string = string.strip()\n",
    "        \n",
    "        if string != \"\":\n",
    "            print(string, flush=True)\n",
    "        \n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 0: Prepare local environment\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 0: Prepare local environment', flush=True)\n",
    "    \n",
    "    os.makedirs(join('input', f'sub-{subject}', f'ses-{session}'), exist_ok=True)\n",
    "    os.makedirs(join('output', f'sub-{subject}', f'ses-{session}'), exist_ok=True)\n",
    "    \n",
    "    def download_dhcp_files(subject, session, fs):\n",
    "        \"\"\"\n",
    "        Download anatomy and DWI files for tractography\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        subject : string\n",
    "        session : string\n",
    "        aws_access_key : string\n",
    "        aws_secret_key : string\n",
    "        \"\"\"\n",
    "        from os.path import exists, join\n",
    "    \n",
    "        anat_files = [\n",
    "            f'sub-{subject}_ses-{session}_desc-drawem87_space-T2w_dseg.nii.gz',\n",
    "            f'sub-{subject}_ses-{session}_desc-drawem9_space-T2w_dseg.nii.gz',\n",
    "            f'sub-{subject}_ses-{session}_desc-restore_T2w.nii.gz',\n",
    "            f'sub-{subject}_ses-{session}_desc-ribbon_space-T2w_dseg.nii.gz'\n",
    "        ]\n",
    "        \n",
    "        for anat_file in anat_files:\n",
    "            if not exists(join('input', f'sub-{subject}', f'ses-{session}', anat_file)):\n",
    "                print('downloading:', anat_file, flush=True)\n",
    "                fs.get(\n",
    "                    (\n",
    "                        f'dhcp-afq/dhcp_anat_pipeline/sub-{subject}/ses-{session}/anat/'\n",
    "                        f'{anat_file}'\n",
    "                    ),\n",
    "                    join('input', f'sub-{subject}', f'ses-{session}', anat_file)\n",
    "                )\n",
    "\n",
    "        dwi_files = [\n",
    "            f'sub-{subject}_ses-{session}_desc-preproc_dwi.bval',\n",
    "            f'sub-{subject}_ses-{session}_desc-preproc_dwi.bvec',\n",
    "            f'sub-{subject}_ses-{session}_desc-preproc_dwi.nii.gz',\n",
    "            f'sub-{subject}_ses-{session}_desc-preproc_space-dwi_brainmask.nii.gz'\n",
    "        ]\n",
    "\n",
    "        for dwi_file in dwi_files:\n",
    "            if not exists(join('input', f'sub-{subject}', f'ses-{session}', dwi_file)):\n",
    "                print('downloading:', dwi_file, flush=True)\n",
    "                fs.get(\n",
    "                    (\n",
    "                        f's3://dhcp-afq/dhcp_dmri_pipeline/sub-{subject}/ses-{session}/dwi/'\n",
    "                        f'{dwi_file}'\n",
    "                    ),\n",
    "                    join('input', f'sub-{subject}', f'ses-{session}', dwi_file)\n",
    "                )\n",
    "    \n",
    "    download_dhcp_files(subject, session, fs)\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 1: Generate isotropic DWI files\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 1: Generate isotropic DWI files', flush=True)\n",
    "    \n",
    "    def reslice_dwi(img_filename, new_zooms=(1.5, 1.5, 1.5)):\n",
    "        \"\"\"\n",
    "        Creates an isotropic dwi file\n",
    "        \n",
    "        In dHCP dataset dwi images have voxel size [1.172 1.172 1.5]\n",
    "        therefore by default scaling to 1.5\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        subject : string\n",
    "        session : string\n",
    "        \"\"\"\n",
    "        import os.path as op\n",
    "        import nibabel as nib\n",
    "        from dipy.align.reslice import reslice\n",
    "\n",
    "        img = nib.load(img_filename)\n",
    "        img_data = img.get_fdata()\n",
    "        img_affine = img.affine\n",
    "        img_zooms = img.header.get_zooms()[:3]\n",
    "        new_data, new_affine = reslice(img_data, img_affine, img_zooms, new_zooms)\n",
    "        new_img = nib.Nifti1Image(new_data, new_affine)\n",
    "\n",
    "        # use original image name as basis for the resliced image name\n",
    "        img_basename = op.basename(img_filename)\n",
    "        desc_index = img_basename.rindex('_')\n",
    "        img_name_start = img_basename[:desc_index]\n",
    "        img_name_end = img_basename[desc_index:]\n",
    "        new_img_filename = op.join('output', f'sub-{subject}', f'ses-{session}', f'{img_name_start}_resliced{img_name_end}')\n",
    "        \n",
    "        print('saving resliced dwi:', new_img_filename, flush=True)\n",
    "        nib.save(new_img, new_img_filename)\n",
    "    \n",
    "    \n",
    "    # dwi\n",
    "    reslice_dwi(join('input', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-preproc_dwi.nii.gz'))\n",
    "\n",
    "    # brainmask\n",
    "    reslice_dwi(join('input', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-preproc_space-dwi_brainmask.nii.gz'))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Step 2: Realign DWI to anatomy using rigid transformation\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 2: Realign DWI to anatomy using rigid transformation', flush=True)\n",
    "\n",
    "    # convert NIFTI to MIF for MRtrix and generate b file\n",
    "    # doing this because MRtrix `works better` with these formats\n",
    "    mrconvert = subprocess.run(\n",
    "        [\n",
    "            'mrconvert',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.nii.gz',\n",
    "            '-fslgrad',\n",
    "            f'input/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_dwi.bvec',\n",
    "            f'input/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_dwi.bval',\n",
    "            '-export_grad_mrtrix',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.b',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.mif'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrconvert.stdout)\n",
    "    print_quiet(mrconvert.stderr)\n",
    "    \n",
    "    # generate b0 from dwi\n",
    "    dwiextract = subprocess.run(\n",
    "        [\n",
    "            'dwiextract',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.mif',\n",
    "            '-grad',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.b',\n",
    "            '-',\n",
    "            '-bzero'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # don't bother printing out since piping to mrmath\n",
    "    # print(dwiextract.stdout)\n",
    "    # print(dwiextract.stderr)\n",
    "    \n",
    "    # pipe dwiextract to mrmath\n",
    "    mrmath = subprocess.run(\n",
    "        [\n",
    "            'mrmath',\n",
    "            '-',\n",
    "            'mean',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-resliced_b0.mif',\n",
    "            '-axis',\n",
    "            '3'\n",
    "        ],\n",
    "        input = dwiextract.stdout,\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrmath.stdout)\n",
    "    print_quiet(mrmath.stderr)\n",
    "        \n",
    "    # registered dwi to anat and extract transform\n",
    "    mrregister = subprocess.run(\n",
    "        [\n",
    "            'mrregister',\n",
    "            '-type',\n",
    "            'rigid',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-resliced_b0.mif',\n",
    "            f'input/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-restore_T2w.nii.gz',\n",
    "            '-transformed',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-resliced_aligned_b0.mif',\n",
    "            '-rigid',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-rigid_transform.txt'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrregister.stdout)\n",
    "    print_quiet(mrregister.stderr)\n",
    "    \n",
    "    # apply transform to dwi\n",
    "    mrtransform = subprocess.run(\n",
    "        [\n",
    "            'mrtransform',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.mif',\n",
    "            '-grad',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.b',\n",
    "            '-export_grad_mrtrix',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.b',\n",
    "            '-linear',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-rigid_transform.txt'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrtransform.stdout)\n",
    "    print_quiet(mrtransform.stderr)\n",
    "    \n",
    "    # export a NIFTI version (for pyafq) with FSL\n",
    "    mrtransform = subprocess.run(\n",
    "        [\n",
    "            'mrtransform',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.nii.gz',\n",
    "            '-grad',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_dwi.b',\n",
    "            '-export_grad_fsl',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.bvec',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.bval',\n",
    "            '-linear',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-rigid_transform.txt'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrtransform.stdout)\n",
    "    print_quiet(mrtransform.stderr)\n",
    "    \n",
    "    # apply transform to brainmask\n",
    "    mrtransform = subprocess.run(\n",
    "        [\n",
    "            'mrtransform',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space-dwi_resliced_brainmask.nii.gz',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space_dwi_resliced_aligned_brainmask.mif',\n",
    "            '-linear',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-rigid_transform.txt'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrtransform.stdout)\n",
    "    print_quiet(mrtransform.stderr)\n",
    "    \n",
    "    # export a NIFTI version (for pyafq)\n",
    "    mrtransform = subprocess.run(\n",
    "        [\n",
    "            'mrtransform',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space-dwi_resliced_brainmask.nii.gz',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space_dwi_resliced_aligned_brainmask.nii.gz',\n",
    "            '-linear',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-rigid_transform.txt'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mrtransform.stdout)\n",
    "    print_quiet(mrtransform.stderr)\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 3: Estimate CSD response function\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 3: Estimate CSD response function', flush=True)\n",
    "    \n",
    "    # tissue response function\n",
    "    dwi2response = subprocess.run(\n",
    "        [\n",
    "            'dwi2response',\n",
    "            'dhollander',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm.txt',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-gm.txt',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csf.txt',\n",
    "            '-mask',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space_dwi_resliced_aligned_brainmask.mif',\n",
    "            '-grad',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.b',\n",
    "            '-voxels',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-voxels.mif',\n",
    "            '-fa',\n",
    "            '0.1'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(dwi2response.stdout)\n",
    "    print_quiet(dwi2response.stderr)\n",
    "    \n",
    "    # CSD estimates\n",
    "    dwi2fod = subprocess.run(\n",
    "        [\n",
    "            'dwi2fod',\n",
    "            'msmt_csd',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm.txt',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csf.txt',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csf.mif',\n",
    "            '-mask',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space_dwi_resliced_aligned_brainmask.mif',\n",
    "            '-grad',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_resliced_aligned_dwi.b'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(dwi2fod.stdout)\n",
    "    print_quiet(dwi2fod.stderr)\n",
    "    \n",
    "    # normalize\n",
    "    mtnormalise = subprocess.run(\n",
    "        [\n",
    "            'mtnormalise',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm_norm.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csf.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csf_norm.mif',\n",
    "            '-mask',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-preproc_space_dwi_resliced_aligned_brainmask.mif'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(mtnormalise.stdout)\n",
    "    print_quiet(mtnormalise.stderr)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Step 4: Reassign ribbon values\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 4: Reassign ribbon values', flush=True)\n",
    "\n",
    "    def update_ribbon(subject, session, dilation_size):\n",
    "        \"\"\"\n",
    "        - do not include ventricles (drawem9 5) as white matter (ribbon 41/2)\n",
    "        - include brainstem (drawem9 8) as white matter (ribbon 41)\n",
    "        - take corpus callosum (drawem87 48)\n",
    "        - dilate the corpus callosum by `dilation_size`\n",
    "        - label dilation as white matter (ribbon 41)\n",
    "    \n",
    "        ensure that there is sufficent white matter around the ventricles \n",
    "        for tracking, while attempting to keep the original gray-white\n",
    "        matter boundary entact everywhere else\n",
    "\n",
    "        TODO: probably could just use the Draw-EM 87\n",
    "        Draw-EM 9 tissue segmentation definitions\n",
    "        s3://dhcp-afq/dhcp_anat_pipeline/desc-drawem9_dseg.tsv\n",
    "        \n",
    "        Draw-EM 87 tissue segmentation definitions\n",
    "        s3://dhcp-afq/dhcp_anat_pipeline/desc-drawem87_dseg.tsv\n",
    "        \n",
    "        Ribbon file uses FreeSurfer definitions\n",
    "        https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT\n",
    "\n",
    "        NOTE: hemisphere designation does not matter as mrtrix merges\n",
    "        using right hemisphere labels\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subject : string\n",
    "        session : string\n",
    "        dilation_size : int\n",
    "        \"\"\"\n",
    "\n",
    "        from os.path import join\n",
    "        import nibabel as nib\n",
    "        import numpy as np\n",
    "        from skimage.morphology import cube, dilation\n",
    "        \n",
    "        ribbon = nib.load(join('input', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-ribbon_space-T2w_dseg.nii.gz'))\n",
    "        ribbon_data = ribbon.get_fdata()\n",
    "        \n",
    "        # dilate the corpus callosum\n",
    "        cc_mask_data = np.zeros(ribbon_data.shape)\n",
    "        drawem87 = nib.load(join('input', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-drawem87_space-T2w_dseg.nii.gz'))\n",
    "        # corpus callosum=48\n",
    "        cc_mask_data[np.where(drawem87.get_fdata()==48)] = 1\n",
    "        dilate_cc_mask_data = dilation(cc_mask_data, cube(dilation_size))\n",
    "        ribbon_data[np.where(dilate_cc_mask_data == 1)] = 41\n",
    "    \n",
    "        # add ventricles back in, in case got overwitten by cc dilation\n",
    "        drawem9 = nib.load(join('input', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-drawem9_space-T2w_dseg.nii.gz'))\n",
    "        # ventricles=5 - label as lateral ventricle left=4 or right=43\n",
    "        ribbon_data[np.where(drawem9.get_fdata() == 5)] = 43\n",
    "\n",
    "        # brainstem=8 - label as white matter left=2 or right=41\n",
    "        ribbon_data[np.where(drawem9.get_fdata() == 8)] = 41\n",
    "\n",
    "        augmented_ribbon = nib.Nifti1Image(ribbon_data, ribbon.affine)\n",
    "        ribbon_file = join('output', f'sub-{subject}', f'ses-{session}', f'sub-{subject}_ses-{session}_desc-ribbon_space_agmntd-T2w_dseg.nii.gz')\n",
    "        print('saving updated ribbon:', ribbon_file, flush=True)\n",
    "        nib.save(augmented_ribbon, ribbon_file)\n",
    "        return ribbon_file\n",
    "\n",
    "    ribbon_file = update_ribbon(subject, session, dilation_size)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Step 5. Generate five-tissue-type (5TT) segmented tissue image\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 5. Generate five-tissue-type (5TT) segmented tissue image', flush=True)\n",
    "\n",
    "    if local_env:\n",
    "        os.environ[\"FREESURFER_HOME\"] = '.'\n",
    "    \n",
    "    # 5tt\n",
    "    fivettgen = subprocess.run(\n",
    "        [\n",
    "            '5ttgen',\n",
    "            'freesurfer',\n",
    "            '-lut',\n",
    "            f'{os.environ[\"FREESURFER_HOME\"]}/FreeSurferColorLUT.txt',\n",
    "            ribbon_file,\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-tt5.mif',\n",
    "            '-nocrop'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(fivettgen.stdout)\n",
    "    print_quiet(fivettgen.stderr)\n",
    "    \n",
    "    # gmwmi\n",
    "    fivett2gmwmi = subprocess.run(\n",
    "        [\n",
    "            '5tt2gmwmi',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-tt5.mif',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-tt5_gmwmi.mif'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(fivett2gmwmi.stdout)\n",
    "    print_quiet(fivett2gmwmi.stderr)\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 6. Tractography\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 6. Tractography', flush=True)\n",
    "\n",
    "    tckgen = subprocess.run(\n",
    "        [\n",
    "            'tckgen',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-wm_norm.mif',\n",
    "            '-algo',\n",
    "            'IFOD1',\n",
    "            '-backtrack',\n",
    "            '-crop_at_gmwmi',\n",
    "            '-seed_gmwmi',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-tt5_gmwmi.mif',\n",
    "            '-act',\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-tt5.mif',\n",
    "            '-angle',\n",
    "            '15',\n",
    "            '-select',\n",
    "            str(streamline_count),\n",
    "            f'output/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_desc-csd_tractography.tck',\n",
    "            '-cutoff',\n",
    "            '0.05'\n",
    "        ],\n",
    "        check = True,\n",
    "        capture_output = True,\n",
    "        text=True\n",
    "    )\n",
    "    print_quiet(tckgen.stdout)\n",
    "    print_quiet(tckgen.stderr)\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 7. Create BIDS derivatives\n",
    "    ###############################################################################\n",
    "    \n",
    "    print('Step 7. Create BIDS dataset_description', flush=True)\n",
    "    \n",
    "    dataset_description = {\n",
    "        \"Name\" : \"dHCP neonatal MRtrix derivatives\",\n",
    "        \"PipelineDescription\" : {\n",
    "            \"Name\" : \"dHCP neonatal MRtrix pipeline\"\n",
    "        },\n",
    "        \"BIDSVersion\" : \"1.4.0\"\n",
    "    }\n",
    "\n",
    "    with open(join('output', 'dataset_description.json'), 'w') as f:\n",
    "        json.dump(dataset_description, f)\n",
    "    \n",
    "    ###############################################################################\n",
    "    # Step 8. Upload to s3\n",
    "    ###############################################################################\n",
    "\n",
    "    # if running locally may be processing multiple subjects, without cleaning\n",
    "    # local directory in between and don't want to reupload same data multiple\n",
    "    # times\n",
    "    if not local_env:\n",
    "        print('Step 8. Upload to s3', flush=True)\n",
    "        \n",
    "        # upload output folder to s3\n",
    "        fs.put('output', 'dhcp-afq/mrtrix/', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Credentials\n",
    "\n",
    "Get DIRECT credentials to download/upload to dhcp-afq S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path as op\n",
    "\n",
    "CP = configparser.ConfigParser()\n",
    "CP.read_file(open(op.join(op.expanduser('~'), '.aws', 'credentials')))\n",
    "CP.sections()\n",
    "\n",
    "aws_access_key = CP.get('default', 'AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = CP.get('default', 'AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "def attach_keys(arr):\n",
    "    return [(e + (aws_access_key, aws_secret_key)) for e in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n"
     ]
    }
   ],
   "source": [
    "def get_subject_session_pair(bucket_path):\n",
    "    \"\"\"\n",
    "    find subject session tuples from s3 file system\n",
    "    \n",
    "    not all subjects have corresponding session data, and some have multiple\n",
    "    \n",
    "    there is no metadata that lists theses pairs, so traverse the bucket\n",
    "    to identify\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bucket_path : string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples containing subject_id and session_id\n",
    "    \"\"\"\n",
    "    import s3fs\n",
    "    fs = s3fs.S3FileSystem()\n",
    "\n",
    "    subject_session_pairs = []\n",
    "\n",
    "    for file in fs.ls(bucket_path):\n",
    "        if fs.isdir(file):\n",
    "            # directory bucket_path/sub-<subid>       \n",
    "            subject = file.split('/')[-1].split('-')[-1]\n",
    "            for file2 in fs.ls(file):\n",
    "                if fs.isdir(file2):\n",
    "                    # directory bucket_path/sub-<subid>/ses-<sesid>\n",
    "                    session = file2.split('/')[-1].split('-')[-1]\n",
    "                    subject_session_pairs.append((subject, session))\n",
    "    \n",
    "    return subject_session_pairs\n",
    "\n",
    "\n",
    "def check_anat_requirements(args):\n",
    "    \"\"\"\n",
    "    not all subjects have ribbon file. \n",
    "    this is common point of failure in pipeline.\n",
    "    remove subject from list.\n",
    "    \"\"\"\n",
    "    \n",
    "    import s3fs\n",
    "    fs = s3fs.S3FileSystem()\n",
    "\n",
    "    return [arg for arg in args if fs.exists(f'dhcp-afq/dhcp_anat_pipeline/sub-{arg[0]}/ses-{arg[1]}/anat/sub-{arg[0]}_ses-{arg[1]}_desc-ribbon_space-T2w_dseg.nii.gz')]\n",
    "\n",
    "\n",
    "# anat and dmri have different subject session pairs 558 and 490 respectively\n",
    "# will only want the intesection\n",
    "dhcp_anat_sub_ses = get_subject_session_pair('dhcp-afq/dhcp_anat_pipeline/')\n",
    "dhcp_dmri_sub_ses = get_subject_session_pair('dhcp-afq/dhcp_dmri_pipeline/')\n",
    "\n",
    "args = sorted(set(dhcp_anat_sub_ses) & set(dhcp_dmri_sub_ses))\n",
    "args = check_anat_requirements(args) # 467 subject/session pairs\n",
    "args = attach_keys(args)\n",
    "print(len(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# first few subjects from dHCP dataset\n",
    "subject_session_tuples = [\n",
    "    ('CC00060XX03', '12501'), \n",
    "    ('CC00062XX05', '13801'),\n",
    "    ('CC00063AN06', '15102'),\n",
    "    ('CC00065XX08', '18600'),\n",
    "    ('CC00066XX09', '19200')\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "attach_keys(subject_session_tuples)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for subject_session_tuple in subject_session_tuples:\n",
    "    print('Begin pipeline:', subject_session_tuple)\n",
    "    \n",
    "    dhcp_tractography_pipeline(\n",
    "        subject_session_tuple[0],\n",
    "        subject_session_tuple[1],\n",
    "        subject_session_tuple[2],\n",
    "        subject_session_tuple[3],\n",
    "        local_env=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shutil\n",
    "shutil.rmtree('input', ignore_errors=True)\n",
    "shutil.rmtree('output', ignore_errors=True)\n",
    "shutil.rmtree('mrtrix', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CloudKnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-04-25T09-49'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().isoformat()[:-7].replace(':','-')[:-3]\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use manjari aws credentials\n",
    "ck.set_profile('dbloom') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify region\n",
    "ck.set_region('us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "Assumes docker image `dhcp`\n",
    "\n",
    "- image was built locally using `./Dockerfile` and `docker build -t dhcp .`\n",
    "\n",
    "- reason was to update MRtrix to 3.0.2, if and when pennbbl/qsiprep includes this version of MRTrix the custom docker image will no longer be necessary."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "! docker build -t dhcp ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerImage = ck.DockerImage(\n",
    "    name = 'dhcp-mrtrix',\n",
    "    func = dhcp_tractography_pipeline,\n",
    "    base_image = 'dhcp:latest',\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "Issue with `pipreqs` generating `requirements.txt`: need to edit and replace `skimage` with `scikit-image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import os.path as op\n",
    "\n",
    "for line in fileinput.input(op.join(dockerImage.build_path, 'requirements.txt'), inplace = True):\n",
    "    print(line.replace('skimage', 'scikit-image').rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677069060729.dkr.ecr.us-west-2.amazonaws.com/cloudknot:dhcp-mrtrix-2021-04-23T09-01\n"
     ]
    }
   ],
   "source": [
    "dockerImage.build(tags=[\"dhcp-mrtrix-\"+ timestamp])\n",
    "repo = ck.aws.DockerRepo(name=ck.get_ecr_repo())\n",
    "dockerImage.push(repo=repo)\n",
    "print(dockerImage.repo_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "cloudknot currently only allows one bucket per profile and bucket names must be unique, therefore must manually create and set active profile."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ck.set_s3_params('cloudknot-dbloom-d4279bd0-c3a4-4637-93a5-c0adb792f0f5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "- `retries` - 3 to reduce chance of spotinstance issues\n",
    "\n",
    "- `bid_percentage` - 105\n",
    "\n",
    "- `max_vcpus` - number of subjects = 490 * `job_def_vcpus`\n",
    "\n",
    "- `volume_size` - 27GB (docker image) + 13GB (data) + 8GB (room for OS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run remaning subject in the 4 regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run subset of subjects"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from functools import reduce\n",
    "\n",
    "def factors(n):    \n",
    "    return set(reduce(list.__add__, ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))\n",
    "\n",
    "max_subjects = 32\n",
    "start_subject = 23\n",
    "number_subjects = [factor for factor in factors(len(args[start_subject:])) if factor < max_subjects][-1]\n",
    "print('bin_size:', number_subjects)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "job_id = 0\n",
    "\n",
    "for arg in bins(args[start_subject:], number_subjects):\n",
    "    result_futures = knot.map(arg, starmap=True)\n",
    "\n",
    "    # sleep two hours before checking every 15 minutes\n",
    "    time.sleep(60*60*2)\n",
    "\n",
    "    while not result_futures.done():\n",
    "        time.sleep(60*15)\n",
    "        \n",
    "    print('job', job_id, ': done!\\n', 'subjects', *next(iter(zip(*arg))), '\\n', knot.jobs[job_id].status)\n",
    "    job_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins(arg_list, bin_size):\n",
    "    return (arg_list[i:i+bin_size] for i in range(0, len(arg_list), bin_size))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "region_names = ['us-east-1', 'us-east-2', 'us-west-1', 'us-west-2']\n",
    "region_args = list(bins(args[151:], 79))\n",
    "\n",
    "for region_name, arg in zip(region_names, region_args):\n",
    "    ck.set_region(region_name)\n",
    "\n",
    "    knot = ck.Knot(\n",
    "        name=region_name + timestamp,\n",
    "        docker_image=dockerImage,\n",
    "        pars_policies=('AmazonS3FullAccess',),\n",
    "        job_def_vcpus=8,\n",
    "        max_vcpus=64,\n",
    "        memory=64000,  # in MB\n",
    "        volume_size=250,  # in GB\n",
    "        instance_types = 'r4.16xlarge'\n",
    "    )\n",
    "    \n",
    "    result_futures = knot.map(arg, starmap=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# arg = list(bins(args[start_subject:],number_subjects))[job_id]\n",
    "# result_futures = knot.map(arg, starmap=True)\n",
    "\n",
    "import time\n",
    "\n",
    "# sleep two hours before checking every 15 minutes\n",
    "# time.sleep(60*60*2)\n",
    "\n",
    "# check job status every 15 minutes\n",
    "while not result_futures.done():\n",
    "    time.sleep(60*15)\n",
    "    \n",
    "job_id = 0\n",
    "print('job', job_id, ': done!\\n', 'subjects', *next(iter(zip(*arg))), '\\n', knot.jobs[job_id].status)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "knot.view_jobs()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "knot.jobs[0].status"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "knot.clobber(clobber_pars=True, clobber_repo=True, clobber_image=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm all arguments processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subjects():\n",
    "    import s3fs\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    for arg in args:\n",
    "        if not fs.exists(f'dhcp-afq/mrtrix/sub-{arg[0]}'):\n",
    "            print(arg[0])\n",
    "            if not fs.exists(f'dhcp-afq/mrtrix/sub-{arg[0]}/ses-{arg[1]}/'):\n",
    "                print(arg[0], arg[1])\n",
    "            \n",
    "check_subjects()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
